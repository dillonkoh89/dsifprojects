{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc0eeb19",
   "metadata": {},
   "source": [
    "## Project 3 Reddit Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e0573",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "I am a data scientist in Reddit and recently, the operation team discover that there is data corruption resulting in a loss of data for recent subreddit posts for these 2 particular subreddits - Parenting and Relationship Advice and they happen to be subreddits which have many members and active. The operation team managed to recover the some data which are basically the posts and their descriptions but not the subreddits which they belong to i.e. Parenting or Relationship Advice. Hence, they have engaged the data team, in particular myself to help them classify these posts to the respective subreddits for them to restore the data.\n",
    "\n",
    "For this problem,, my proposed soution will be two-fold:\n",
    "1. Using [Pushshift's](https://github.com/pushshift/api) API, I will collect posts from the two subreddits - Parenting and Relationship Advice.\n",
    "2. I will then use NLP to train a classifier on which subreddit a given post came from. This is a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47720ea8",
   "metadata": {},
   "source": [
    "### Reading data from the Reddit API\n",
    "\n",
    "I will use the Pushshift's API to import reddit posts from both subreddits and then store them in a DataFrame for further processing in the second notebook to prevent unncessary importing when running the notebook.\n",
    "\n",
    "The 2 subreddits and their information about the community (subreddit) are shown below:\n",
    "- **Parenting** - /r/Parenting is the place to discuss the ins and out as well as ups and downs of child-rearing. From the early stages of pregnancy to when your teenagers are finally ready to leave the nest (even if they don't want to) we're here to help you through this crazy thing called parenting. You can get advice on potty training, talk about breastfeeding, discuss how to get your baby to sleep or ask if that one weird thing your kid does is normal.\n",
    "\n",
    "\n",
    "- **Relationship Advice** -  A community to help in relationships whether it's romance, friendship, family, co-workers, or basic human interaction: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b0f23",
   "metadata": {},
   "source": [
    "### Data retrieval and initial processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac0e9a",
   "metadata": {},
   "source": [
    "I have created a key function get_redditposts() to import all the data and features from the 2 selected subreddits by repeating the importing of data using the API as the API only limits a maximum of 100 posts for each request. The function will require an input of the number of times I would like to call the API to get the number of entries required. The subsequent posts will be imported using the timestamp of the last entry of the previous request which the created_utc is the earliest of the 100 posts. Then I will use the timestamp and the before parameter in the API to import another 100 posts before the timestamp.\n",
    "\n",
    "For this project, I have used a count of 20 times to import data in the individual subreddit. There are a total of 72 different data fields obtained from calling the API. However, for this project, I am only using the subreddit post title and and post text/description to train the classifer. Hence, I have only kept 3 columns which are required this will explained in the data section below.\n",
    "\n",
    "After getting the dataframe with the 3 relevant fields, I have removed duplicate posts first by considering the title column followed by the selftext column as Reddit ‘jams’ your webscraping by giving you duplicate posts.\n",
    "\n",
    "Finally, i concatenate both dataframes for both subreddits into 1 combined dataframe, saved to a csv file. This file will then be used in the second python notebook for further processing, modelling and training the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d356fbf",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6877c4e4",
   "metadata": {},
   "source": [
    "The data were collected by reading from the Reddit API on Friday September 03, 2021 between 2.50pm and 2.55pm for the final data to be used in my project. This is done after exploring the API, data imported earlier in the week. As mentioned above, there are a total of 72 data fields extracted from the API such as created_utc (creation time), author_fullname (ID of the author) and etc. However, i am only interested in the following fields for my projects. Hence, i created a dataframe to only collect these 3 fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3866b0",
   "metadata": {},
   "source": [
    "\n",
    "| **Column**  | **Description**  |\n",
    "| :-|:-|\n",
    "| subreddit  | subreddit category housing this post  |\n",
    "| selftext   | Text of the post  |\n",
    "| title  | post title |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a67232",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74da3a",
   "metadata": {},
   "source": [
    "- https://docs.python.org/3/library/time.html\n",
    "- https://github.com/pushshift/api\n",
    "- https://youtu.be/AcrjEWsMi_E\n",
    "- https://www.reddit.com/r/relationship_advice/\n",
    "- https://www.reddit.com/r/Parenting/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3b889",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9ec648",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a1de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link for pushshift api\n",
    "url = 'https://api.pushshift.io/reddit/search/submission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7a14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract more data and combining into 1 dataframe based on 1 subreddit\n",
    "def get_redditposts(post, count):\n",
    "    \n",
    "    # get the current time\n",
    "    ts = int(time.time())\n",
    "    \n",
    "    # get 100 posts from the selected subreddit before the timestamp\n",
    "    params = {'subreddit': post,\n",
    "             'size' : 100,\n",
    "             'before' : ts}\n",
    "    \n",
    "    print(\"No. of retrieval: 1\")\n",
    "    \n",
    "    # get the request and status code\n",
    "    res = requests.get(url, params)\n",
    "    print(\"Status Code is \" + str(res.status_code))\n",
    "    print(\"------------------\")\n",
    "    data = res.json()\n",
    "    posts = data['data']\n",
    "    df = pd.DataFrame(posts)\n",
    "    df_combined = df.copy()\n",
    "    ts = posts[-1]['created_utc']\n",
    "    \n",
    "    if count == 1:\n",
    "        \n",
    "        return df_combined\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(count-1):\n",
    "            print('No. of retrieval: '+ str(i+2))\n",
    "            params = {'subreddit': post,\n",
    "                 'size' : 100,\n",
    "                 'before' : ts}\n",
    "            res = requests.get(url, params)\n",
    "            print(\"Status Code is \" + str(res.status_code))\n",
    "            print(\"------------------\")\n",
    "            data = res.json()\n",
    "            posts = data['data']\n",
    "            df = pd.DataFrame(posts)\n",
    "            df_combined = df_combined.append(df, sort=False)\n",
    "            ts = posts[-1]['created_utc']\n",
    "\n",
    "        return df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c16329",
   "metadata": {},
   "source": [
    "### Retrieving and Processing of the Data from subreddit Parenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b75f179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of retrieval: 1\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 2\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 3\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 4\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 5\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 6\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 7\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 8\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 9\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 10\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 11\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 12\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 13\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 14\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 15\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 16\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 17\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 18\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 19\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 20\n",
      "Status Code is 200\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# Getting the pots for subreddit \"Parenting\"\n",
    "df_parenting = get_redditposts('parenting', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c4f586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for any duplicated considering the created_utc which is the time where the post is created.\n",
    "df_parenting['created_utc'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e6ced6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'allow_live_comments', 'author',\n",
       "       'author_flair_css_class', 'author_flair_richtext', 'author_flair_text',\n",
       "       'author_flair_type', 'author_fullname', 'author_is_blocked',\n",
       "       'author_patreon_flair', 'author_premium', 'awarders', 'can_mod_post',\n",
       "       'contest_mode', 'created_utc', 'domain', 'full_link', 'gildings', 'id',\n",
       "       'is_created_from_ads_ui', 'is_crosspostable', 'is_meta',\n",
       "       'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable',\n",
       "       'is_self', 'is_video', 'link_flair_background_color',\n",
       "       'link_flair_css_class', 'link_flair_richtext', 'link_flair_template_id',\n",
       "       'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked',\n",
       "       'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18',\n",
       "       'parent_whitelist_status', 'permalink', 'pinned', 'pwls',\n",
       "       'retrieved_on', 'score', 'selftext', 'send_replies', 'spoiler',\n",
       "       'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers',\n",
       "       'subreddit_type', 'thumbnail', 'title', 'total_awards_received',\n",
       "       'treatment_tags', 'upvote_ratio', 'url', 'whitelist_status', 'wls',\n",
       "       'post_hint', 'preview', 'removed_by_category',\n",
       "       'author_flair_template_id', 'author_flair_text_color',\n",
       "       'author_flair_background_color', 'edited', 'author_cakeday',\n",
       "       'crosspost_parent', 'crosspost_parent_list', 'url_overridden_by_dest',\n",
       "       'banned_by'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the columns for the data imported from the API\n",
    "df_parenting.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc0fb56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  2000 non-null   object\n",
      " 1   selftext   1996 non-null   object\n",
      " 2   title      2000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# saving the 3 key columns into a new dataframe for futher processing and using info function to check the dataframe\n",
    "df_parenting1 = df_parenting[['subreddit', 'selftext', 'title']]\n",
    "df_parenting1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ae52c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicates row based on selftext and title columns but keeping the first occurence\n",
    "df_parenting1.drop_duplicates(subset=['title'], keep='first', inplace=True)\n",
    "df_parenting1.drop_duplicates(subset=['selftext'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ed2b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1580 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  1580 non-null   object\n",
      " 1   selftext   1579 non-null   object\n",
      " 2   title      1580 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 49.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# using the info function to check for the null values and number of rows\n",
    "df_parenting1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cfd3353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>So I live with a 3 year old who constantly hit...</td>\n",
       "      <td>Is it normal for a 3 year old to hit constantly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>My son just turned 7, and at times he seems li...</td>\n",
       "      <td>Normal common sense in a child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>My son is 6 months old and I'm fully aware thi...</td>\n",
       "      <td>Getting bruised by a baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>My 8 year old is terrible to get out of the be...</td>\n",
       "      <td>Morning routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>TW: PPD\\n\\nMy 17 month old is a tornado and th...</td>\n",
       "      <td>My house is trashed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>These days you can find out everything has som...</td>\n",
       "      <td>Soon to be a new parent; does anyone have a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>This is probably an unpopular opinion. When an...</td>\n",
       "      <td>Over the “Check-in”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>I am finding motherhood a struggle.  I love my...</td>\n",
       "      <td>Motherhood a struggle (33f with 2yo son)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>My son is 3 now and I’m trying to potty train ...</td>\n",
       "      <td>Diaper Change Fights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>Hi! My daughter is turning one soon and becaus...</td>\n",
       "      <td>1st birthday time capsule</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                           selftext  \\\n",
       "0  Parenting  So I live with a 3 year old who constantly hit...   \n",
       "1  Parenting  My son just turned 7, and at times he seems li...   \n",
       "2  Parenting  My son is 6 months old and I'm fully aware thi...   \n",
       "3  Parenting  My 8 year old is terrible to get out of the be...   \n",
       "4  Parenting  TW: PPD\\n\\nMy 17 month old is a tornado and th...   \n",
       "5  Parenting  These days you can find out everything has som...   \n",
       "6  Parenting  This is probably an unpopular opinion. When an...   \n",
       "7  Parenting  I am finding motherhood a struggle.  I love my...   \n",
       "8  Parenting  My son is 3 now and I’m trying to potty train ...   \n",
       "9  Parenting  Hi! My daughter is turning one soon and becaus...   \n",
       "\n",
       "                                               title  \n",
       "0    Is it normal for a 3 year old to hit constantly  \n",
       "1                  Normal common sense in a child...  \n",
       "2                          Getting bruised by a baby  \n",
       "3                                    Morning routine  \n",
       "4                             My house is trashed...  \n",
       "5  Soon to be a new parent; does anyone have a co...  \n",
       "6                                Over the “Check-in”  \n",
       "7           Motherhood a struggle (33f with 2yo son)  \n",
       "8                               Diaper Change Fights  \n",
       "9                          1st birthday time capsule  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the head function to see the first 10 rows of the dataframe.\n",
    "df_parenting1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6551d5",
   "metadata": {},
   "source": [
    "### Retrieving and Processing of the Data from subreddit Relationship Advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec8f307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of retrieval: 1\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 2\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 3\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 4\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 5\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 6\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 7\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 8\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 9\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 10\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 11\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 12\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 13\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 14\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 15\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 16\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 17\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 18\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 19\n",
      "Status Code is 200\n",
      "------------------\n",
      "No. of retrieval: 20\n",
      "Status Code is 200\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# Getting the pots for subreddit \"Life Pro Tips\"\n",
    "df_rshipadvice = get_redditposts('relationship_advice', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba127ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1986"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for any duplicated considering the created_utc which is the time where the post is created.\n",
    "df_rshipadvice['created_utc'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5d06538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  2000 non-null   object\n",
      " 1   selftext   1999 non-null   object\n",
      " 2   title      2000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# saving the 3 key columns into a new dataframe for futher processing and using info function to check the dataframe\n",
    "df_rshipadvice1 = df_rshipadvice[['subreddit', 'selftext', 'title']]\n",
    "df_rshipadvice1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "932be2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicates row based on selftext and title columns but keeping the first occurence\n",
    "df_rshipadvice1.drop_duplicates(subset=['title'], keep='first', inplace=True)\n",
    "df_rshipadvice1.drop_duplicates(subset=['selftext'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b69d44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1684 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  1684 non-null   object\n",
      " 1   selftext   1683 non-null   object\n",
      " 2   title      1684 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 52.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# using the info function to check for the null values and number of rows\n",
    "df_rshipadvice1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "563f8075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>How much is it normal or acceptable for couple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>\\nI really just want to break something. Havin...</td>\n",
       "      <td>I want to break something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>I need some advices in how to get back my girl...</td>\n",
       "      <td>I need some advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>This is kind of long but I’ll make it short\\nF...</td>\n",
       "      <td>Physical affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>So for some context, my ex and I dated for 3 y...</td>\n",
       "      <td>My [21M] ex gf [20F] wants to hang out with my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>Sorry for formatting issues, I’m on mobile. Th...</td>\n",
       "      <td>Am I [26F] delusional for thinking my brother ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>Earlier tonight I called my brother because I ...</td>\n",
       "      <td>Need advice for me and my brother’s relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>So this was my first proper relationship. My e...</td>\n",
       "      <td>I (26f) broke up with my boyfriend (25m) about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>This is less about a relationship issue but I ...</td>\n",
       "      <td>My feelings are hurt, but should they be??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>Do you think it’s normal to find ur man attrac...</td>\n",
       "      <td>Physically attracted to a guy but having hard ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit                                           selftext  \\\n",
       "0   relationship_advice                                          [removed]   \n",
       "1   relationship_advice  \\nI really just want to break something. Havin...   \n",
       "3   relationship_advice  I need some advices in how to get back my girl...   \n",
       "4   relationship_advice  This is kind of long but I’ll make it short\\nF...   \n",
       "5   relationship_advice  So for some context, my ex and I dated for 3 y...   \n",
       "6   relationship_advice  Sorry for formatting issues, I’m on mobile. Th...   \n",
       "7   relationship_advice  Earlier tonight I called my brother because I ...   \n",
       "8   relationship_advice  So this was my first proper relationship. My e...   \n",
       "9   relationship_advice  This is less about a relationship issue but I ...   \n",
       "10  relationship_advice  Do you think it’s normal to find ur man attrac...   \n",
       "\n",
       "                                                title  \n",
       "0   How much is it normal or acceptable for couple...  \n",
       "1                          I want to break something.  \n",
       "3                                  I need some advice  \n",
       "4                                  Physical affection  \n",
       "5   My [21M] ex gf [20F] wants to hang out with my...  \n",
       "6   Am I [26F] delusional for thinking my brother ...  \n",
       "7    Need advice for me and my brother’s relationship  \n",
       "8   I (26f) broke up with my boyfriend (25m) about...  \n",
       "9          My feelings are hurt, but should they be??  \n",
       "10  Physically attracted to a guy but having hard ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the head function to see the first 10 rows of the dataframe.\n",
    "df_rshipadvice1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "679c6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_parenting1, df_rshipadvice1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ff4b96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>So I live with a 3 year old who constantly hit...</td>\n",
       "      <td>Is it normal for a 3 year old to hit constantly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>My son just turned 7, and at times he seems li...</td>\n",
       "      <td>Normal common sense in a child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>My son is 6 months old and I'm fully aware thi...</td>\n",
       "      <td>Getting bruised by a baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>My 8 year old is terrible to get out of the be...</td>\n",
       "      <td>Morning routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parenting</td>\n",
       "      <td>TW: PPD\\n\\nMy 17 month old is a tornado and th...</td>\n",
       "      <td>My house is trashed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>i’ve been talking to this guy for almost a yea...</td>\n",
       "      <td>What do i mean to him?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>I, a cis male, teenage, have liked girls my en...</td>\n",
       "      <td>What do I do now that I know I like them?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>I, (16M) are currently dating my partner, T (1...</td>\n",
       "      <td>It feels like my partner likes making me jealo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>TLDR: He has had past with some girls. He che...</td>\n",
       "      <td>Boyfriend(24M) of 3 years keeps checking out o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>My girlfriend and I have been not on the same ...</td>\n",
       "      <td>Ughhh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3264 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                subreddit                                           selftext  \\\n",
       "0               Parenting  So I live with a 3 year old who constantly hit...   \n",
       "1               Parenting  My son just turned 7, and at times he seems li...   \n",
       "2               Parenting  My son is 6 months old and I'm fully aware thi...   \n",
       "3               Parenting  My 8 year old is terrible to get out of the be...   \n",
       "4               Parenting  TW: PPD\\n\\nMy 17 month old is a tornado and th...   \n",
       "...                   ...                                                ...   \n",
       "3259  relationship_advice  i’ve been talking to this guy for almost a yea...   \n",
       "3260  relationship_advice  I, a cis male, teenage, have liked girls my en...   \n",
       "3261  relationship_advice  I, (16M) are currently dating my partner, T (1...   \n",
       "3262  relationship_advice   TLDR: He has had past with some girls. He che...   \n",
       "3263  relationship_advice  My girlfriend and I have been not on the same ...   \n",
       "\n",
       "                                                  title  \n",
       "0       Is it normal for a 3 year old to hit constantly  \n",
       "1                     Normal common sense in a child...  \n",
       "2                             Getting bruised by a baby  \n",
       "3                                       Morning routine  \n",
       "4                                My house is trashed...  \n",
       "...                                                 ...  \n",
       "3259                             What do i mean to him?  \n",
       "3260          What do I do now that I know I like them?  \n",
       "3261  It feels like my partner likes making me jealo...  \n",
       "3262  Boyfriend(24M) of 3 years keeps checking out o...  \n",
       "3263                                              Ughhh  \n",
       "\n",
       "[3264 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1fa3ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relationship_advice    1684\n",
       "Parenting              1580\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using value counts to check the number of rows for each subreddit\n",
    "df_final['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d18aa68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the df_final to csv for further processing in the second python notebook to prevent multiple scrapping using the api\n",
    "df_final.to_csv(\"Combined Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cfe77d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
